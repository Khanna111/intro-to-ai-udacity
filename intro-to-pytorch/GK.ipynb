{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --------- \n",
      "\n",
      "tensor([0])\n",
      "torch.Size([1])\n",
      "\n",
      "1 --------- \n",
      "\n",
      "tensor([[0]])\n",
      "torch.Size([1, 1])\n",
      "\n",
      "2 --------- \n",
      "\n",
      "tensor([], dtype=torch.int64)\n",
      "torch.Size([0])\n",
      "\n",
      "3 --------- \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# shapes of torch tensors\n",
    "# ---------------------------\n",
    "\n",
    "j = 0\n",
    "\n",
    "print(\"%d --------- \\n\" % j)\n",
    "i = torch.arange(10).resize_(1)\n",
    "print(i)\n",
    "print(i.shape)\n",
    "\n",
    "j += 1\n",
    "print(\"\\n%d --------- \\n\" %j)\n",
    "i = torch.arange(10).resize_(1,1)\n",
    "print(i)\n",
    "print(i.shape)\n",
    "\n",
    "j += 1\n",
    "print(\"\\n%d --------- \\n\" %j)\n",
    "i = torch.arange(10).resize_(0)\n",
    "print(i)\n",
    "print(i.shape)\n",
    "\n",
    "j += 1\n",
    "print(\"\\n%d --------- \\n\" %j)\n",
    "i = torch.arange(10).resize_(2,3)\n",
    "print(i)\n",
    "print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1.shape torch.Size([3])\n",
      "softmax: tensor([0.3333, 0.3333, 0.3333], grad_fn=<SoftmaxBackward>) \n",
      "\n",
      "\n",
      "input1.shape torch.Size([3])\n",
      "softmax: tensor([0.1554, 0.4223, 0.4223], grad_fn=<SoftmaxBackward>) \n",
      "\n",
      "\n",
      "input1.shape torch.Size([1, 3])\n",
      "softmax: tensor([[0.1554, 0.4223, 0.4223]], grad_fn=<SoftmaxBackward>) \n"
     ]
    }
   ],
   "source": [
    "# SoftMax\n",
    "# -----------------\n",
    "# input is of size N x C = 1 \n",
    "input1 = torch.tensor([0,0,0], requires_grad=True, dtype=torch.float)\n",
    "print(\"input1.shape {}\".format(input1.shape))\n",
    "m_smx = nn.Softmax(dim=0)\n",
    "print(\"softmax: {} \".format(m_smx(input1)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# input is of size N x C = 1 \n",
    "input1 = torch.tensor([0,1,1], requires_grad=True, dtype=torch.float)\n",
    "print(\"input1.shape {}\".format(input1.shape))\n",
    "m_smx = nn.Softmax(dim=0)\n",
    "print(\"softmax: {} \".format(m_smx(input1)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# input is of size N x C = 1 x 3\n",
    "input1 = torch.tensor([[0,1,1]], requires_grad=True, dtype=torch.float)\n",
    "print(\"input1.shape {}\".format(input1.shape))\n",
    "m_smx = nn.Softmax(dim=1)\n",
    "print(\"softmax: {} \".format(m_smx(input1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input2.shape torch.Size([3])\n",
      "log softmax: tensor([-1.0986, -1.0986, -1.0986], grad_fn=<LogSoftmaxBackward>) \n",
      "\n",
      "\n",
      "input2.shape torch.Size([3])\n",
      "log softmax: tensor([-1.8620, -0.8620, -0.8620], grad_fn=<LogSoftmaxBackward>) \n"
     ]
    }
   ],
   "source": [
    "# LogSoftMax\n",
    "# -----------------\n",
    "# input is of size N x C = 1 \n",
    "input2 = torch.tensor([0,0,0], requires_grad=True, dtype=torch.float)\n",
    "print(\"input2.shape {}\".format(input2.shape))\n",
    "m_log_smx = nn.LogSoftmax(dim=0)\n",
    "print(\"log softmax: {} \".format(m_log_smx(input2)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# input is of size N x C = 1\n",
    "input2 = torch.tensor([0,1,1], requires_grad=True, dtype=torch.float)\n",
    "print(\"input2.shape {}\".format(input2.shape))\n",
    "m_log_smx = nn.LogSoftmax(dim=0)\n",
    "print(\"log softmax: {} \".format(m_log_smx(input2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3333, 0.3333, 0.3333])\n"
     ]
    }
   ],
   "source": [
    "# Convert LogSoftMax output into SoftMax\n",
    "# -------------------------\n",
    "input3 = torch.tensor([-1.0986, -1.0986, -1.0986])\n",
    "print(torch.exp(input3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X: tensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\ntopk: tensor([[4, 3],\n        [9, 8]])\nindices: tensor([[4, 3],\n        [4, 3]])\n"
    }
   ],
   "source": [
    "# topk\n",
    "# ----------------\n",
    "x = torch.arange(0,10).resize_((2,5))\n",
    "print (\"X: {}\".format(x))\n",
    "\n",
    "# topk => the top 2 values in the rows \n",
    "topk, indices = torch.topk(x,2)\n",
    "print(\"topk: {}\".format(topk))\n",
    "print(\"indices: {}\".format(indices))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Slicing and zip\n",
    "# ---------------\n",
    "l = [512, 256, 128]\n",
    "print(l[:-1])     # begin:end-1\n",
    "print(l[1:])      # begin+1:end\n",
    "layer_sizes = zip(l[:-1], l[1:])\n",
    "[print(\"h1, h2: {}, {}\".format(h1, h2)) for h1, h2 in layer_sizes]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[512, 256]\n[256, 128]\nh1, h2: 512, 256\nh1, h2: 256, 128\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[None, None]"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "X.shape: torch.Size([2, 5])\n",
      "\n",
      "\n",
      "max: tensor([5, 6, 7, 8, 9])\n",
      "index: tensor([1, 1, 1, 1, 1])\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# max\n",
    "# --------------------------\n",
    "import torch\n",
    "\n",
    "x = torch.arange(0,10).resize_((2,5))\n",
    "print (\"X: {}\".format(x))\n",
    "print (\"X.shape: {}\".format(x.shape))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Returns the max in each row for given dim\n",
    "max, index = x.max(1)\n",
    "\n",
    "print(\"max: {}\".format(max))\n",
    "print(\"index: {}\".format(index))\n",
    "print(max[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Returns the max in each column (by collapsing dim 0 (rows)) for given dim\n",
    "max, index = x.max(0)\n",
    "print(\"max: {}\".format(max))\n",
    "print(\"index: {}\".format(index))\n",
    "print(max[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41916509 -0.49870665  1.63070857]\n",
      " [ 1.21679659 -0.5698281  -1.16761079]\n",
      " [-1.18229229 -0.84897776 -1.89130183]]\n",
      "[ 1.63070857  1.21679659 -0.84897776]\n",
      "\n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([ 1.6307,  1.2168, -0.8490], dtype=torch.float64),\n",
      "indices=tensor([2, 0, 1]))\n",
      "tensor([ 1.6307,  1.2168, -0.8490], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy max vs torch max\n",
    "# --------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(3, 3)\n",
    "print (x)\n",
    "print(x.max(1))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(torch.from_numpy(x).max(1))\n",
    "# [0] => max values\n",
    "# [1] => indices of max values\n",
    "print(torch.from_numpy(x).max(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}