{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --------- \n",
      "\n",
      "tensor([0])\n",
      "torch.Size([1])\n",
      "\n",
      "1 --------- \n",
      "\n",
      "tensor([[0]])\n",
      "torch.Size([1, 1])\n",
      "\n",
      "2 --------- \n",
      "\n",
      "tensor([], dtype=torch.int64)\n",
      "torch.Size([0])\n",
      "\n",
      "3 --------- \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# shapes of torch tensors\n",
    "# ---------------------------\n",
    "\n",
    "j = 0\n",
    "\n",
    "print(\"%d --------- \\n\" % j)\n",
    "i = torch.arange(10).resize_(1)\n",
    "print(i)\n",
    "print(i.shape)\n",
    "\n",
    "j += 1\n",
    "print(\"\\n%d --------- \\n\" %j)\n",
    "i = torch.arange(10).resize_(1,1)\n",
    "print(i)\n",
    "print(i.shape)\n",
    "\n",
    "j += 1\n",
    "print(\"\\n%d --------- \\n\" %j)\n",
    "i = torch.arange(10).resize_(0)\n",
    "print(i)\n",
    "print(i.shape)\n",
    "\n",
    "j += 1\n",
    "print(\"\\n%d --------- \\n\" %j)\n",
    "i = torch.arange(10).resize_(2,3)\n",
    "print(i)\n",
    "print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1.shape torch.Size([3])\n",
      "softmax: tensor([0.3333, 0.3333, 0.3333], grad_fn=<SoftmaxBackward>) \n",
      "\n",
      "\n",
      "input1.shape torch.Size([3])\n",
      "softmax: tensor([0.1554, 0.4223, 0.4223], grad_fn=<SoftmaxBackward>) \n",
      "\n",
      "\n",
      "input1.shape torch.Size([1, 3])\n",
      "softmax: tensor([[0.1554, 0.4223, 0.4223]], grad_fn=<SoftmaxBackward>) \n"
     ]
    }
   ],
   "source": [
    "# SoftMax\n",
    "# -----------------\n",
    "# input is of size N x C = 1 \n",
    "input1 = torch.tensor([0,0,0], requires_grad=True, dtype=torch.float)\n",
    "print(\"input1.shape {}\".format(input1.shape))\n",
    "m_smx = nn.Softmax(dim=0)\n",
    "print(\"softmax: {} \".format(m_smx(input1)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# input is of size N x C = 1 \n",
    "input1 = torch.tensor([0,1,1], requires_grad=True, dtype=torch.float)\n",
    "print(\"input1.shape {}\".format(input1.shape))\n",
    "m_smx = nn.Softmax(dim=0)\n",
    "print(\"softmax: {} \".format(m_smx(input1)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# input is of size N x C = 1 x 3\n",
    "input1 = torch.tensor([[0,1,1]], requires_grad=True, dtype=torch.float)\n",
    "print(\"input1.shape {}\".format(input1.shape))\n",
    "m_smx = nn.Softmax(dim=1)\n",
    "print(\"softmax: {} \".format(m_smx(input1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input2.shape torch.Size([3])\n",
      "log softmax: tensor([-1.0986, -1.0986, -1.0986], grad_fn=<LogSoftmaxBackward>) \n",
      "\n",
      "\n",
      "input2.shape torch.Size([3])\n",
      "log softmax: tensor([-1.8620, -0.8620, -0.8620], grad_fn=<LogSoftmaxBackward>) \n"
     ]
    }
   ],
   "source": [
    "# LogSoftMax\n",
    "# -----------------\n",
    "# input is of size N x C = 1 \n",
    "input2 = torch.tensor([0,0,0], requires_grad=True, dtype=torch.float)\n",
    "print(\"input2.shape {}\".format(input2.shape))\n",
    "m_log_smx = nn.LogSoftmax(dim=0)\n",
    "print(\"log softmax: {} \".format(m_log_smx(input2)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# input is of size N x C = 1\n",
    "input2 = torch.tensor([0,1,1], requires_grad=True, dtype=torch.float)\n",
    "print(\"input2.shape {}\".format(input2.shape))\n",
    "m_log_smx = nn.LogSoftmax(dim=0)\n",
    "print(\"log softmax: {} \".format(m_log_smx(input2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3333, 0.3333, 0.3333])\n"
     ]
    }
   ],
   "source": [
    "# Convert LogSoftMax output into SoftMax\n",
    "# -------------------------\n",
    "input3 = torch.tensor([-1.0986, -1.0986, -1.0986])\n",
    "print(torch.exp(input3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X: tensor([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]])\ntopk: tensor([[4, 3],\n        [9, 8]])\nindices: tensor([[4, 3],\n        [4, 3]])\nindices: tensor([[3, 2],\n        [3, 2]])\n"
    }
   ],
   "source": [
    "# topk\n",
    "# ----------------\n",
    "x = torch.arange(0,10).resize_((2,5))\n",
    "print (\"X: {}\".format(x))\n",
    "\n",
    "# topk => the top 2 values in the rows \n",
    "topk, indices = torch.topk(x,2)\n",
    "print(\"topk: {}\".format(topk))\n",
    "print(\"indices: {}\".format(indices))\n",
    "\n",
    "indices = indices - 1\n",
    "\n",
    "print(\"indices: {}\".format(indices))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Slicing and zip\n",
    "# ---------------\n",
    "l = [512, 256, 128]\n",
    "print(l[:-1])     # begin:end-1\n",
    "print(l[1:])      # begin+1:end\n",
    "layer_sizes = zip(l[:-1], l[1:])\n",
    "[print(\"h1, h2: {}, {}\".format(h1, h2)) for h1, h2 in layer_sizes]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[512, 256]\n[256, 128]\nh1, h2: 512, 256\nh1, h2: 256, 128\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[None, None]"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "X.shape: torch.Size([2, 5])\n",
      "\n",
      "\n",
      "max: tensor([5, 6, 7, 8, 9])\n",
      "index: tensor([1, 1, 1, 1, 1])\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# max\n",
    "# --------------------------\n",
    "import torch\n",
    "\n",
    "x = torch.arange(0,10).resize_((2,5))\n",
    "print (\"X: {}\".format(x))\n",
    "print (\"X.shape: {}\".format(x.shape))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Returns the max in each row for given dim\n",
    "max, index = x.max(1)\n",
    "\n",
    "print(\"max: {}\".format(max))\n",
    "print(\"index: {}\".format(index))\n",
    "print(max[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Returns the max in each column (by collapsing dim 0 (rows)) for given dim\n",
    "max, index = x.max(0)\n",
    "print(\"max: {}\".format(max))\n",
    "print(\"index: {}\".format(index))\n",
    "print(max[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41916509 -0.49870665  1.63070857]\n",
      " [ 1.21679659 -0.5698281  -1.16761079]\n",
      " [-1.18229229 -0.84897776 -1.89130183]]\n",
      "[ 1.63070857  1.21679659 -0.84897776]\n",
      "\n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([ 1.6307,  1.2168, -0.8490], dtype=torch.float64),\n",
      "indices=tensor([2, 0, 1]))\n",
      "tensor([ 1.6307,  1.2168, -0.8490], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy max vs torch max\n",
    "# --------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(3, 3)\n",
    "print (x)\n",
    "print(x.max(1))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(torch.from_numpy(x).max(1))\n",
    "# [0] => max values\n",
    "# [1] => indices of max values\n",
    "print(torch.from_numpy(x).max(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 5])\ntorch.Size([5])\n5\nsnapdragon\n15\ngiant white arum lily\n74\nrose\n75\nthorn apple\n69\nmoon orchid\n['snapdragon', 'giant white arum lily', 'rose', 'thorn apple', 'moon orchid']\n"
    }
   ],
   "source": [
    "# List Comprehension, Torch to numpy\n",
    "# -----------------------------------------\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "idx_to_class = {0: '1', 1: '10', 2: '100', 3: '101', 4: '102', 5: '11', 6: '12', 7: '13', 8: '14', 9: '15', 10: '16', 11: '17', 12: '18', 13: '19', 14: '2', 15: '20', 16: '21', 17: '22', 18: '23', 19: '24', 20: '25', 21: '26', 22: '27', 23: '28', 24: '29', 25: '3', 26: '30', 27: '31', 28: '32', 29: '33', 30: '34', 31: '35', 32: '36', 33: '37', 34: '38', 35: '39', 36: '4', 37: '40', 38: '41', 39: '42', 40: '43', 41: '44', 42: '45', 43: '46', 44: '47', 45: '48', 46: '49', 47: '5', 48: '50', 49: '51', 50: '52', 51: '53', 52: '54', 53: '55', 54: '56', 55: '57', 56: '58', 57: '59', 58: '6', 59: '60', 60: '61', 61: '62', 62: '63', 63: '64', 64: '65', 65: '66', 66: '67', 67: '68', 68: '69', 69: '7', 70: '70', 71: '71', 72: '72', 73: '73', 74: '74', 75: '75', 76: '76', 77: '77', 78: '78', 79: '79', 80: '8', 81: '80', 82: '81', 83: '82', 84: '83', 85: '84', 86: '85', 87: '86', 88: '87', 89: '88', 90: '89', 91: '9', 92: '90', 93: '91', 94: '92', 95: '93', 96: '94', 97: '95', 98: '96', 99: '97', 100: '98', 101: '99'}\n",
    "\n",
    "cat_to_name = {'21': 'fire lily', '3': 'canterbury bells', '45': 'bolero deep blue', '1': 'pink primrose', '34': 'mexican aster', '27': 'prince of wales feathers', '7': 'moon orchid', '16': 'globe-flower', '25': 'grape hyacinth', '26': 'corn poppy', '79': 'toad lily', '39': 'siam tulip', '24': 'red ginger', '67': 'spring crocus', '35': 'alpine sea holly', '32': 'garden phlox', '10': 'globe thistle', '6': 'tiger lily', '93': 'ball moss', '33': 'love in the mist', '9': 'monkshood', '102': 'blackberry lily', '14': 'spear thistle', '19': 'balloon flower', '100': 'blanket flower', '13': 'king protea', '49': 'oxeye daisy', '15': 'yellow iris', '61': 'cautleya spicata', '31': 'carnation', '64': 'silverbush', '68': 'bearded iris', '63': 'black-eyed susan', '69': 'windflower', '62': 'japanese anemone', '20': 'giant white arum lily', '38': 'great masterwort', '4': 'sweet pea', '86': 'tree mallow', '101': 'trumpet creeper', '42': 'daffodil', '22': 'pincushion flower', '2': 'hard-leaved pocket orchid', '54': 'sunflower', '66': 'osteospermum', '70': 'tree poppy', '85': 'desert-rose', '99': 'bromelia', '87': 'magnolia', '5': 'english marigold', '92': 'bee balm', '28': 'stemless gentian', '97': 'mallow', '57': 'gaura', '40': 'lenten rose', '47': 'marigold', '59': 'orange dahlia', '48': 'buttercup', '55': 'pelargonium', '36': 'ruby-lipped cattleya', '91': 'hippeastrum', '29': 'artichoke', '71': 'gazania', '90': 'canna lily', '18': 'peruvian lily', '98': 'mexican petunia', '8': 'bird of paradise', '30': 'sweet william', '17': 'purple coneflower', '52': 'wild pansy', '84': 'columbine', '12': \"colt's foot\", '11': 'snapdragon', '96': 'camellia', '23': 'fritillary', '50': 'common dandelion', '44': 'poinsettia', '53': 'primula', '72': 'azalea', '65': 'californian poppy', '80': 'anthurium', '76': 'morning glory', '37': 'cape flower', '56': 'bishop of llandaff', '60': 'pink-yellow dahlia', '82': 'clematis', '58': 'geranium', '75': 'thorn apple', '41': 'barbeton daisy', '95': 'bougainvillea', '43': 'sword lily', '83': 'hibiscus', '78': 'lotus lotus', '88': 'cyclamen', '94': 'foxglove', '81': 'frangipani', '74': 'rose', '89': 'watercress', '73': 'water lily', '46': 'wallflower', '77': 'passion flower', '51': 'petunia'}\n",
    "\n",
    "topk = torch.FloatTensor([[ 0.5765,  0.1567,  0.0612,  0.0301,  0.0256]])\n",
    "indices = torch.tensor([[  5,  15,  74,  75,  69]])\n",
    "\n",
    "print(indices.shape)\n",
    "indices = torch.flatten(indices, start_dim=0)\n",
    "print(indices.shape)\n",
    "\n",
    "for x in indices.numpy():\n",
    "    print (x)\n",
    "    print(cat_to_name[idx_to_class[x]])\n",
    "\n",
    "list_cat_names_from_indices = [cat_to_name[idx_to_class[x]] for x in indices.numpy()]\n",
    "\n",
    "print(list_cat_names_from_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}